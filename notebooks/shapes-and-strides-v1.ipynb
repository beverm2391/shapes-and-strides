{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import Tuple, List\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*With a single-segment of memory representing the array, the one-dimensional index into computer memory can always be computed from the N-dimensional index*\n",
    "\n",
    "Let $n_i$ be the value of the ith index into an array whose shape is represented by the $N$ integers $d_i (i = 0\\ .\\ .\\ . N − 1)$. Then, the one-dimensional index into a C-style contiguous array is\n",
    "$$n^C = \\sum_{i=0}^{N-1}n_i\\prod^{N-1}_{j=i+1}d_j$$\n",
    "while the one-dimensional index into a Fortran-style array is\n",
    "$$n^F = \\sum_{i=0}^{N-1}n_i\\prod_{j=0}^{N-1}d_j$$\n",
    "In these formulas we are assuming that\n",
    "$$\\prod_{j=k}^{m}d_j=d_k d_{k+1}...d_{m-1} d_m$$\n",
    "\n",
    "Let’s see how they expand out for determining the one-dimensional index corresponding to the element (1, 3, 2) of a 4 × 5 × 6 array. If the array is stored as Fortran contiguous, then\n",
    "$$n_F = n_0 \\cdot (1) + n_1 \\cdot (4) + n_2 \\cdot (4 \\cdot 5)$$\n",
    "$$ = 1 + 3 \\cdot 4 + 3 \\cdot 20 = 53$$\n",
    "On the other hand, if the array is stored as $C$ contiguous, then\n",
    "$$n^{C}=n_0 \\cdot (5 \\cdot 6) + n_1 \\cdot (6) + n_2 \\cdot (1)$$\n",
    "$$ = 1 \\cdot 30 + 3 \\cdot 6 + 2 \\cdot 1 = 50$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "array is (4 x 5 x 6)\n",
    "indices = (1, 3, 2)\n",
    "C-style linear index = 1 * (5*6) + 3 * (6) + 2 * (1) = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +=: 'int' and 'ellipsis'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m         sum_ \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m indices[i] \u001b[38;5;241m*\u001b[39m accumulate(shape[i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m:]) \u001b[38;5;66;03m# all remaining shapes\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m: \u001b[38;5;66;03m# last element\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m         sum_ \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m indices[i]\n\u001b[1;32m     13\u001b[0m linear_index_cstyle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m([(indices[i] \u001b[38;5;241m*\u001b[39m accumulate(shape[i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m:]) \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(indices) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m indices[i]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(indices))])\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mNDArray\u001b[39;00m:\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +=: 'int' and 'ellipsis'"
     ]
    }
   ],
   "source": [
    "indices = [...]\n",
    "shape = [...]\n",
    "\n",
    "def accumulate(arr): return (el := arr[0]) * accumulate(arr[1:]) if arr else 1\n",
    "\n",
    "sum_ = 0\n",
    "for i in range(len(indices)):\n",
    "    if i<len(indices)-1: # if were not on the last element\n",
    "        sum_ += indices[i] * accumulate(shape[i+1:]) # all remaining shapes\n",
    "    else: # last element\n",
    "        sum_ += indices[i]\n",
    "\n",
    "linear_index_cstyle = sum([(indices[i] * accumulate(shape[i+1:]) if i < len(indices) - 1 else indices[i]) for i in range(len(indices))])\n",
    "\n",
    "class NDArray:\n",
    "    def __init__(self, shape: Tuple[int, ...], data: List[float]):\n",
    "        self.size = accumulate(shape)\n",
    "        if len(data) != self.size: raise Exception(\"Data size does not match shape\")\n",
    "        self.shape = shape\n",
    "        self.data = data\n",
    "\n",
    "    def _ndim_to_cstyle(self, indices: Tuple[int, ...]):\n",
    "        return sum([(indices[i] * accumulate(shape[i+1:]) if i < len(indices) - 1 else indices[i]) for i in range(len(indices))])\n",
    "\n",
    "    def __getitem__(self, indices: Tuple[int, ...]):\n",
    "        if len(indices) != len(self.shape): raise Exception(\"Indices do not match shape\")\n",
    "        linear_index_cstyle = self._ndim_to_cstyle(indices)\n",
    "        assert linear_index_cstyle < self.size, \"Index out of bounds - something went wrong\"\n",
    "        return self.data[linear_index_cstyle]\n",
    "    \n",
    "    def __setitem__(self, indices: Tuple[int, ...], value: float):\n",
    "        if len(indices) != len(self.shape): raise Exception(\"Indices do not match shape\")\n",
    "        linear_index_cstyle = self._ndim_to_cstyle(indices)\n",
    "        assert linear_index_cstyle < self.size, \"Index out of bounds - something went wrong\"\n",
    "        self.data[linear_index_cstyle] = value\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"NDArray(shape={self.shape}, data={self.data})\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The formulas for the one-dimensional index of the N-dimensional arrays reveal what results in an important generalization for memory layout. Notice that each\n",
    "formula can be written as\n",
    "\n",
    "$$n^X = \\sum^{N-1}_{i=1}n_i s^x_i$$\n",
    "\n",
    "where $s^x_i$ gives the *stride* for dimension *i*. Thus, for C and Fortran arrays respectively we have:\n",
    "$$s^C_i = \\prod^{N-1}_{j=i+1}d_j=d_{i+1}d_{i+2}\\cdots d_{N-1},$$\n",
    "$$s^F_i = \\prod^{i-1}_{j=0}d_j=d_0d_1\\cdots d_{i-1}$$\n",
    "\n",
    "The stride is how many **elements** in the underlying one-dimensional layout of the array one must jump in order to get to the next array element of a specific dimension in the N-dimensional layout. Thus, in a C-style 4x5x6 array one must jump over 30 elements to increment the first index by one, so 30 is the stride for the first dimension $s^C_0 = 30$. If, for each array, we define a strides Tuple with $N$ integers, the we have pre-computed and stored the important piece of how to map the N-dimensional index to the one-dimensional one used by the computer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "an index on an array always produces an ndarray object (but with different strides) - this is what a *view* is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accumulater(arr): return (el := arr[0]) * accumulate(arr[1:]) if arr else 1\n",
    "def flatten(iterable: List):\n",
    "    if not isinstance(iterable, list): return [iterable]\n",
    "    return [el for sublist in iterable for el in flatten(sublist)]\n",
    "\n",
    "class Ndarray:\n",
    "    def __init__(self, shape: Tuple[int, ...], data: List[float]):\n",
    "        self.size = self.numel = accumulate(shape) # the total number of elements in the array\n",
    "        self.shape: Tuple = shape # the shape of the array\n",
    "        self.data: List = data # the buffer will do here\n",
    "        self.stride_size: int = 8 #? if this = 1, strides is the number of elements to skip, if this = 8, strides is the number of bytes to skip\n",
    "        self.strides: Tuple = self._calculate_strides()\n",
    "        self.itemsize: int = 4 # itemsize is the number of bytes per element (dtype). thus 4*8 = 32 bits (float32)\n",
    "        self.bytes = self.size * self.itemsize # total number of bytes in the array\n",
    "        self.iscontiguous = True # if the array is contiguous in memory\n",
    "\n",
    "        # validate\n",
    "        if len(data) != self.size: raise Exception(\"Data size does not match shape\")\n",
    "\n",
    "    # strides\n",
    "    def _calculate_strides(self):\n",
    "        strides = [0 for _ in self.shape] # make an empty strides tuple\n",
    "        for i in range(len(self.shape)): # for each dim\n",
    "            stride = self.stride_size # start with the stride size\n",
    "            for j in range(i+1, len(self.shape)): # accumulate the rest of the dims up to the N-1 dim\n",
    "                stride *= self.shape[j]\n",
    "            strides[i] = stride # set the stride in the Tuple\n",
    "        return tuple(strides) # return the tuple\n",
    "    \n",
    "    def __getitem__(self, indices: Tuple[int,...]):\n",
    "        def _check(self, indices): \n",
    "            if len(indices) != len(self.shape): raise Exception(\"Indices do not match shape\")\n",
    "            for i in range(len(indices)):\n",
    "                if indices[i] >= self.shape[i]: raise Exception(\"Index out of bounds\")\n",
    "                if indices[i] < 0: raise Exception(\"Index out of bounds\")\n",
    "    \n",
    "        _check(self, indices)\n",
    "\n",
    "        linear_index = 0\n",
    "        for i in range(len(indices)):\n",
    "            linear_index += indices[i] * self.strides[i]\n",
    "            \n",
    "        return self.data[linear_index]\n",
    "\n",
    "    @staticmethod\n",
    "    def array(data: List):\n",
    "        return NDArray((len(data),), data)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"Ndarray(shape={self.shape}, strides={self.strides}, data={self.data})\"\n",
    "    \n",
    "\n",
    "def test_ndarray():\n",
    "    shape = (3, 4, 5)\n",
    "    data = [random.randint(0, 10) for _ in range(accumulate(shape))]\n",
    "\n",
    "    arr = Ndarray(shape, data)\n",
    "    np_arr = np.array(data).reshape(shape)\n",
    "\n",
    "    assert arr.data == flatten(np_arr.data.tolist()), \"data mismatch\"\n",
    "    assert arr.shape == np_arr.shape, \"shape mismatch\"\n",
    "    assert arr.strides == np_arr.strides, \"strides mismatch\"\n",
    "\n",
    "test_ndarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = (3, 4, 5)\n",
    "data = [random.randint(0, 10) for _ in range(accumulate(shape))]\n",
    "\n",
    "arr = Ndarray(shape, data)\n",
    "np_arr = np.array(data).reshape(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'flatten'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mnp_arr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtolist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'flatten'"
     ]
    }
   ],
   "source": [
    "np_arr.data.tolist().flatten()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
